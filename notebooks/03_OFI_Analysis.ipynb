{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed22464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594dfc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df  = pd.read_csv('../data/hawkes_analysis_data.csv')\n",
    "df  = pd.read_csv(r'I:/Hawkes_Model_MM/hawkes_analysis_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2382db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_number</th>\n",
       "      <th>trade_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>buy_order_number</th>\n",
       "      <th>buy_algo</th>\n",
       "      <th>buy_client</th>\n",
       "      <th>sell_order_number</th>\n",
       "      <th>sell_algo</th>\n",
       "      <th>sell_client</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>buy_entry_ts</th>\n",
       "      <th>sell_entry_ts</th>\n",
       "      <th>aggressor_side</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019081325008066</td>\n",
       "      <td>785.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1100000000068964</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1100000000062580</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-13 09:15:00.006118774</td>\n",
       "      <td>2019-08-13 09:15:00.005767822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019081325008128</td>\n",
       "      <td>785.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1100000000069441</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1100000000062580</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-13 09:15:00.024169922</td>\n",
       "      <td>2019-08-13 09:15:00.024139404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019081325008129</td>\n",
       "      <td>785.0</td>\n",
       "      <td>47</td>\n",
       "      <td>1100000000069442</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1100000000062580</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-13 09:15:00.024230957</td>\n",
       "      <td>2019-08-13 09:15:00.024215698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019081325008130</td>\n",
       "      <td>785.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1100000000069442</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1100000000068983</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-13 09:15:00.024246216</td>\n",
       "      <td>2019-08-13 09:15:00.024215698</td>\n",
       "      <td>2019-08-13 09:15:00.005935669</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019081325008466</td>\n",
       "      <td>785.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1100000000055032</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1100000000070554</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-13 09:15:00.118347168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-13 09:15:00.118331909</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trade_number  trade_price  volume  buy_order_number  buy_algo  \\\n",
       "0  2019081325008066        785.0       1  1100000000068964         1   \n",
       "1  2019081325008128        785.0       2  1100000000069441         1   \n",
       "2  2019081325008129        785.0      47  1100000000069442         1   \n",
       "3  2019081325008130        785.0      53  1100000000069442         1   \n",
       "4  2019081325008466        785.0      10  1100000000055032         1   \n",
       "\n",
       "   buy_client  sell_order_number  sell_algo  sell_client  \\\n",
       "0           2   1100000000062580          1            3   \n",
       "1           3   1100000000062580          1            3   \n",
       "2           3   1100000000062580          1            3   \n",
       "3           3   1100000000068983          0            3   \n",
       "4           3   1100000000070554          0            1   \n",
       "\n",
       "                       timestamp                   buy_entry_ts  \\\n",
       "0  2019-08-13 09:15:00.006118774  2019-08-13 09:15:00.005767822   \n",
       "1  2019-08-13 09:15:00.024169922  2019-08-13 09:15:00.024139404   \n",
       "2  2019-08-13 09:15:00.024230957  2019-08-13 09:15:00.024215698   \n",
       "3  2019-08-13 09:15:00.024246216  2019-08-13 09:15:00.024215698   \n",
       "4  2019-08-13 09:15:00.118347168                            NaN   \n",
       "\n",
       "                   sell_entry_ts  aggressor_side        date  \n",
       "0                            NaN              -1  2019-08-13  \n",
       "1                            NaN              -1  2019-08-13  \n",
       "2                            NaN              -1  2019-08-13  \n",
       "3  2019-08-13 09:15:00.005935669               1  2019-08-13  \n",
       "4  2019-08-13 09:15:00.118331909               1  2019-08-13  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04dda37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c604922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a0c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = dates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf77301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_day = df[df['date'] == target_date].sort_values('timestamp')\n",
    "df_day = df[df['date'] == target_date].sort_values(['timestamp', 'trade_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e43e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['timestamp'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eee0cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_open = pd.to_datetime((target_date) + ' 09:15:00')\n",
    "df_day['t'] = (df_day['timestamp'] - market_open).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62530a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_times = df_day[df_day['aggressor_side'] == +1]['t'].to_numpy()\n",
    "sell_times = df_day[df_day['aggressor_side'] == -1]['t'].to_numpy()\n",
    "\n",
    "events = [buy_times, sell_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e580911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay = 1/60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f4e85b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba not available. Install with: pip install numba\n"
     ]
    }
   ],
   "source": [
    "from BivariateHawkes_optimized import BivariateHawkesOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a729c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BivariateHawkesOptimized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dbe4534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BivariateHawkes_optimized.BivariateHawkesOptimized at 0x1c012170430>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(buy_times, sell_times, optimize_beta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb57f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "699ca69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu_buy': np.float64(1e-10),\n",
       " 'mu_sell': np.float64(1.5922560349197657e-05),\n",
       " 'alpha_bb': np.float64(11110.233936482926),\n",
       " 'alpha_bs': np.float64(4328.096228617026),\n",
       " 'alpha_sb': np.float64(3885.0443986418936),\n",
       " 'alpha_ss': np.float64(9725.6813823859),\n",
       " 'beta': np.float64(24563.963992568843),\n",
       " 'br_bb': np.float64(0.4522980875498769),\n",
       " 'br_bs': np.float64(0.17619697822087566),\n",
       " 'br_sb': np.float64(0.15816031971945602),\n",
       " 'br_ss': np.float64(0.3959328952496486),\n",
       " 'spectral_radius': np.float64(0.5934129489553213),\n",
       " 'total_branching': np.float64(1.1825882807398571),\n",
       " 'log_likelihood': np.float64(1470278.0284006584),\n",
       " 'is_stationary': np.True_}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be2ae82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu_buy</th>\n",
       "      <th>mu_sell</th>\n",
       "      <th>alpha_bb</th>\n",
       "      <th>alpha_bs</th>\n",
       "      <th>alpha_sb</th>\n",
       "      <th>alpha_ss</th>\n",
       "      <th>beta</th>\n",
       "      <th>br_bb</th>\n",
       "      <th>br_bs</th>\n",
       "      <th>br_sb</th>\n",
       "      <th>br_ss</th>\n",
       "      <th>spectral_radius</th>\n",
       "      <th>total_branching</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>is_stationary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>11110.233936</td>\n",
       "      <td>4328.096229</td>\n",
       "      <td>3885.044399</td>\n",
       "      <td>9725.681382</td>\n",
       "      <td>24563.963993</td>\n",
       "      <td>0.452298</td>\n",
       "      <td>0.176197</td>\n",
       "      <td>0.15816</td>\n",
       "      <td>0.395933</td>\n",
       "      <td>0.593413</td>\n",
       "      <td>1.182588</td>\n",
       "      <td>1470278.028401</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mu_buy   mu_sell      alpha_bb     alpha_bs     alpha_sb  \\\n",
       "2019-08-13    0.0  0.000016  11110.233936  4328.096229  3885.044399   \n",
       "\n",
       "               alpha_ss          beta     br_bb     br_bs    br_sb     br_ss  \\\n",
       "2019-08-13  9725.681382  24563.963993  0.452298  0.176197  0.15816  0.395933   \n",
       "\n",
       "           spectral_radius total_branching  log_likelihood is_stationary  \n",
       "2019-08-13        0.593413        1.182588  1470278.028401          True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({target_date: results}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "439f8e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.42462160e-02, 1.18347168e-01, 3.17398071e-01, ...,\n",
       "       2.42857539e+04, 2.42857539e+04, 2.42857539e+04])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e236e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_day_results = {target_date: results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a35c34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2019-08-13': {'mu_buy': np.float64(1e-10),\n",
       "  'mu_sell': np.float64(1.5922560349197657e-05),\n",
       "  'alpha_bb': np.float64(11110.233936482926),\n",
       "  'alpha_bs': np.float64(4328.096228617026),\n",
       "  'alpha_sb': np.float64(3885.0443986418936),\n",
       "  'alpha_ss': np.float64(9725.6813823859),\n",
       "  'beta': np.float64(24563.963992568843),\n",
       "  'br_bb': np.float64(0.4522980875498769),\n",
       "  'br_bs': np.float64(0.17619697822087566),\n",
       "  'br_sb': np.float64(0.15816031971945602),\n",
       "  'br_ss': np.float64(0.3959328952496486),\n",
       "  'spectral_radius': np.float64(0.5934129489553213),\n",
       "  'total_branching': np.float64(1.1825882807398571),\n",
       "  'log_likelihood': np.float64(1470278.0284006584),\n",
       "  'is_stationary': np.True_}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_day_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "834861d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     r \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_results()\n\u001b[0;32m     11\u001b[0m     all_day_results[target_date] \u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m---> 12\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_day_results\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/all_day_results.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\ml3\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\ml3\\lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3975\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3977\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3978\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3979\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3983\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3984\u001b[0m )\n\u001b[1;32m-> 3986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3989\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3991\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4003\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\ml3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\ml3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\ml3\\lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\ml3\\lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..\\data'"
     ]
    }
   ],
   "source": [
    "for target_date in dates[1:]:\n",
    "    df_day = df[df['date'] == target_date].sort_values(['timestamp', 'trade_number'])\n",
    "    market_open = pd.to_datetime((target_date) + ' 09:15:00')\n",
    "    df_day['t'] = (df_day['timestamp'] - market_open).dt.total_seconds()\n",
    "    buy_times = df_day[df_day['aggressor_side'] == +1]['t'].to_numpy()\n",
    "    sell_times = df_day[df_day['aggressor_side'] == -1]['t'].to_numpy()\n",
    "    events = [buy_times, sell_times]\n",
    "    model = BivariateHawkesOptimized()\n",
    "    model.fit(buy_times, sell_times, optimize_beta=True)\n",
    "    r = model.get_results()\n",
    "    all_day_results[target_date] = r\n",
    "pd.DataFrame(all_day_results).T.to_csv('../data/all_day_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "036cebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_day_results).T.to_csv('../data/all_day_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b23f5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_day_results).T.to_csv('all_day_results_{}.csv'.format(target_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a5c6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MarkedBivariateHawkes_optimized import MarkedBivariateHawkesOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88b4012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/10: 2019-08-13...\n",
      "Processing 2/10: 2019-08-14...\n",
      "Processing 3/10: 2019-08-16...\n",
      "Processing 4/10: 2019-08-19...\n",
      "Processing 5/10: 2019-08-20...\n",
      "Processing 6/10: 2019-08-21...\n",
      "Processing 7/10: 2019-08-22...\n",
      "Processing 8/10: 2019-08-23...\n",
      "Processing 9/10: 2019-08-26...\n",
      "Processing 10/10: 2019-08-27...\n",
      "\n",
      "Completed: 10/10 dates\n",
      "Saved to: ../data/all_day_marked_results.csv\n",
      "              mu_buy   mu_sell      alpha_bb      alpha_bs     alpha_sb  \\\n",
      "2019-08-13       0.0   0.00005   1413.224351   1351.644465   484.358717   \n",
      "2019-08-14  0.000058       0.0   2972.043103    603.450777   647.627549   \n",
      "2019-08-16  0.001694       0.0   1399.760427    289.769062   643.928139   \n",
      "2019-08-19       0.0  0.001814   2503.635706    751.308251  1012.084692   \n",
      "2019-08-20  0.030899       0.0  25357.324177  10285.932356  4820.213991   \n",
      "\n",
      "                alpha_ss          beta  avg_mark     br_bb     br_bs  \\\n",
      "2019-08-13   1569.618928  10376.059644  2.716042  0.369926  0.353807   \n",
      "2019-08-14   3214.557979  10530.310853  2.655542  0.749492  0.152179   \n",
      "2019-08-16   1500.988531   4998.900858  2.600939  0.728298  0.150767   \n",
      "2019-08-19   2724.352546   9037.600882  2.480952  0.687284  0.206245   \n",
      "2019-08-20  24472.820543      100000.0  2.903157  0.736163  0.298617   \n",
      "\n",
      "               br_sb     br_ss spectral_radius total_branching  \\\n",
      "2019-08-13  0.126786  0.410864        0.603178        1.261383   \n",
      "2019-08-14  0.163319   0.81065         0.94066         1.87564   \n",
      "2019-08-16  0.335037  0.780968        0.980921         1.99507   \n",
      "2019-08-19  0.277832  0.747874        0.958866        1.919235   \n",
      "2019-08-20  0.139938  0.710484        0.928147        1.885202   \n",
      "\n",
      "            log_likelihood is_stationary  \n",
      "2019-08-13  1351100.134825          True  \n",
      "2019-08-14  1324903.832932          True  \n",
      "2019-08-16     989368.7902          True  \n",
      "2019-08-19   882652.692502          True  \n",
      "2019-08-20  1398866.893976          True  \n"
     ]
    }
   ],
   "source": [
    "# Cell: Process all dates with marked Hawkes (similar to all_day_results)\n",
    "all_day_marked_results = {}\n",
    "\n",
    "for i, target_date in enumerate(dates):\n",
    "    print(f\"Processing {i+1}/{len(dates)}: {target_date}...\")\n",
    "    \n",
    "    # Prepare data for the day\n",
    "    df_day = df[df['date'] == target_date].sort_values(['timestamp', 'trade_number'])\n",
    "    market_open = pd.to_datetime((target_date) + ' 09:15:00')\n",
    "    df_day['t'] = (df_day['timestamp'] - market_open).dt.total_seconds()\n",
    "    \n",
    "    # Extract buy and sell events with volumes\n",
    "    buy_mask = df_day['aggressor_side'] == +1\n",
    "    sell_mask = df_day['aggressor_side'] == -1\n",
    "    \n",
    "    buy_times = df_day[buy_mask]['t'].to_numpy()\n",
    "    sell_times = df_day[sell_mask]['t'].to_numpy()\n",
    "    buy_volumes = df_day[buy_mask]['volume'].to_numpy()\n",
    "    sell_volumes = df_day[sell_mask]['volume'].to_numpy()\n",
    "    \n",
    "    # Skip if insufficient data\n",
    "    if len(buy_times) < 10 or len(sell_times) < 10:\n",
    "        print(f\"  Skipping: insufficient events\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Fit marked Hawkes model\n",
    "        model = MarkedBivariateHawkesOptimized()\n",
    "        model.fit(buy_times, sell_times, buy_volumes, sell_volumes, \n",
    "                  optimize_beta=True, verbose=False)\n",
    "        \n",
    "        # Store results\n",
    "        all_day_marked_results[target_date] = model.get_results()\n",
    "        pd.DataFrame(all_day_marked_results).T.to_csv('all_day_marked_results_{}.csv'.format(target_date))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nCompleted: {len(all_day_marked_results)}/{len(dates)} dates\")\n",
    "\n",
    "# Cell: Save results as DataFrame\n",
    "df_marked_results = pd.DataFrame(all_day_marked_results).T\n",
    "df_marked_results.to_csv('../data/all_day_marked_results.csv')\n",
    "print(f\"Saved to: ../data/all_day_marked_results.c\n",
    "sv\")\n",
    "print(df_marked_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763c067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
